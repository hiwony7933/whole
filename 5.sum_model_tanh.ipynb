{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 압축해제\n",
    "!unzip x-ray.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## path 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "images_path = './images/'   # WGAN image 저장 폴더\n",
    "models_path = './models/'   # 각 model 저장 폴더   \n",
    "npy_path = './npy/'         # npy 배열 저장 폴더 \n",
    "path_category_ = [images_path, models_path, npy_path]\n",
    "\n",
    "for idx, folder in enumerate(path_category_) : \n",
    "    if os.path.isdir(folder) : \n",
    "        print(folder, 'Made')\n",
    "    else : \n",
    "        os.mkdir(folder)\n",
    "        print(folder, 'Make')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# 이미지 path\n",
    "fracture_path = './x-ray/fracture_resize_reverse_crop/'\n",
    "normal_path = './x-ray/Normal_resize_reverse_crop/'\n",
    "\n",
    "# 이미지 증강 path\n",
    "generate_fracture_path = './x-ray/generate_fracture/'\n",
    "generate_normal_path ='./x-ray/generate_normal/'\n",
    "path_category = [generate_fracture_path, generate_normal_path]\n",
    "\n",
    "# path folders Make \n",
    "for idx, folder in enumerate(path_category) :\n",
    "    if os.path.isdir(folder) : \n",
    "        shutil.rmtree(folder)   # 폴더가 만들어져 있으면 기존의 폴더 지우고 \n",
    "        os.mkdir(folder)        # 새로 생성함.\n",
    "        print(folder, 'Folders Make!!')\n",
    "    else : \n",
    "        os.mkdir(folder)        # 폴더가 없으면 새로 생성\n",
    "        print(folder, 'Folders Make!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 전처리 \n",
    "* 이미지 증강 X10\n",
    "* 이미지 로드하면서 equalization \n",
    "* 로드된 이미지 numpy 배열변환\n",
    "* -1~1 normalization \n",
    "* fracture only train - fracture_train.npy \n",
    "* normal only train - normal_train.npy \n",
    "* classification train - classify_train.npy (X_train_c, X_test, Y_train_c, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, sys, numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "\n",
    "# images.shape = (None, 224, 244). value = 0~225\n",
    "def equalize_images(images):\n",
    "    return np.array([cv2.equalizeHist(image) for image in images])\n",
    "    \n",
    "def generate_images_for_data_augmentation(original_path, output_path, prefix, max_gen_count):\n",
    "    #create_output_path(output_path)\n",
    "    \n",
    "    file_list = os.listdir(original_path)\n",
    "    \n",
    "    datagen = ImageDataGenerator(  \n",
    "                rotation_range=10,\n",
    "                width_shift_range=0.01,\n",
    "                height_shift_range=0.01,\n",
    "                #shear_range=0.2,\n",
    "                zoom_range=0.1,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode=\"nearest\")\n",
    "    \n",
    "    for filename in tqdm(file_list) :\n",
    "        # copy\n",
    "        shutil.copyfile(original_path + filename, output_path + filename)\n",
    "        \n",
    "        # generates\n",
    "        img = load_img(original_path  + filename)  # this is a PIL image\n",
    "        \n",
    "        img_data = img_to_array(img) # this is a Numpy array\n",
    "        img_data = img_data.reshape((1,) + img_data.shape)  # this is a Numpy array \n",
    "\n",
    "        # the .flow() command below generates batches of randomly transformed images\n",
    "        # and saves the results to the `preview/` directory\n",
    "        generated_count = 0\n",
    "        \n",
    "        for batch in datagen.flow(img_data, batch_size = 1, save_to_dir=output_path, save_prefix=prefix, save_format=\"jpg\"):\n",
    "            generated_count += 1\n",
    "\n",
    "            if generated_count > max_gen_count:\n",
    "                break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 증강\n",
    "generate_images_for_data_augmentation(fracture_path, generate_fracture_path, '', 10)\n",
    "generate_images_for_data_augmentation(normal_path, generate_normal_path, '', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN_Data_set - facture_only\n",
    "X = []\n",
    "\n",
    "for file_name in tqdm(glob.glob(generate_fracture_path + '*.jpg')) :\n",
    "    img = Image.open(file_name).convert('L')\n",
    "    data = np.array(img)\n",
    "    # equalization\n",
    "    data = equalize_images(data) \n",
    "    X.append(data)\n",
    "\n",
    "fracture_train = np.array(X)\n",
    "# normalization -1 ~ 1\n",
    "fracture_train = (fracture_train - 127.5) / 127.5\n",
    "print(fracture_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fracutre_train 저장\n",
    "np.save('./npy/fracture_train.npy',fracture_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal data set \n",
    "X_ = []\n",
    "\n",
    "for file_name in tqdm(glob.glob(generate_normal_path + '*.jpg')) :\n",
    "    img = Image.open(file_name).convert('L')\n",
    "    data = np.array(img)\n",
    "    # equalization\n",
    "    data = equalize_images(data)\n",
    "    X_.append(data)\n",
    "\n",
    "normal_train = np.array(X_)\n",
    "# normalization -1 ~ 1\n",
    "normal_train = (normal_train - 127.5) / 127.5\n",
    "print(normal_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_train 저장\n",
    "np.save('./npy/normal_train.npy',normal_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classfication 사용할 Data set 만들기\n",
    "# fracture 와 normal data 1:1 비율\n",
    "\n",
    "# normal_train 개수 확인 \n",
    "train_len = normal_train.shape[0]\n",
    "normal_train_x = normal_train\n",
    "\n",
    "# facture data 개수를 Normal_data 개수와 맞추기 \n",
    "fracture_train_x = fracture_train[ : train_len]\n",
    "\n",
    "# y_label create\n",
    "normal_train_y = np.zeros((train_len, 1)) # 비골절 0\n",
    "fracture_train_y = np.ones((train_len, 1)) # 골절 1\n",
    "\n",
    "print('normal data',normal_train_x.shape, normal_train_y.shape)\n",
    "print('facture data',fracture_train_x.shape, fracture_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fracture + normal \n",
    "x = np.append(normal_train_x, fracture_train_x, axis = 0)\n",
    "y = np.append(normal_train_y, fracture_train_y, axis = 0)\n",
    "\n",
    "# data shuffle\n",
    "shuffled_index = np.random.permutation(x.shape[0])\n",
    "x = x[shuffled_index,:,:]\n",
    "y = y[shuffled_index]\n",
    "\n",
    "# data ready \n",
    "split_index = int(x.shape[0] * 0.9)\n",
    "X_train_c, X_test = x[:split_index], x[split_index:]\n",
    "Y_train_c, Y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "print('X_train', X_train_c.shape)\n",
    "print('X_test ', X_test.shape)\n",
    "print('Y_train', Y_train_c.shape)\n",
    "print('Y_test ', Y_test.shape)\n",
    "\n",
    "print(Y_test[:5]) # 0과 1이 섞여 있으면 suffle 성공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify_train 저장\n",
    "xy = (X_train_c, X_test, Y_train_c, Y_test)\n",
    "np.save('./npy/classify_train.npy', xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGAN 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "fracture_train = np.load('./npy/fracture_train.npy', allow_pickle=True)\n",
    "\n",
    "print(fracture_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "from functools import partial\n",
    "\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((32, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "class WGANGP():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build the generator and critic\n",
    "        self.generator = self.build_generator()\n",
    "        self.critic = self.build_critic()\n",
    "\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the Critic\n",
    "        #-------------------------------\n",
    "\n",
    "        # Freeze generator's layers while training critic\n",
    "        self.generator.trainable = False\n",
    "\n",
    "        # Image input (real sample)\n",
    "        real_img = Input(shape=self.img_shape)\n",
    "\n",
    "        # Noise input\n",
    "        z_disc = Input(shape=(self.latent_dim,))\n",
    "        # Generate image based of noise (fake sample)\n",
    "        fake_img = self.generator(z_disc)\n",
    "\n",
    "        # Discriminator determines validity of the real and fake images\n",
    "        fake = self.critic(fake_img)\n",
    "        valid = self.critic(real_img)\n",
    "\n",
    "        # Construct weighted average between real and fake images\n",
    "        interpolated_img = RandomWeightedAverage()([real_img, fake_img])\n",
    "        # Determine validity of weighted sample\n",
    "        validity_interpolated = self.critic(interpolated_img)\n",
    "\n",
    "        # Use Python partial to provide loss function with additional\n",
    "        # 'averaged_samples' argument\n",
    "        partial_gp_loss = partial(self.gradient_penalty_loss, averaged_samples=interpolated_img)\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "        self.critic_model = Model(inputs=[real_img, z_disc],outputs=[valid, fake, validity_interpolated])\n",
    "        self.critic_model.compile(loss=[self.wasserstein_loss, self.wasserstein_loss, partial_gp_loss],\n",
    "                                  optimizer=optimizer,\n",
    "                                  loss_weights=[1, 1, 10])\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.critic.trainable = False\n",
    "        self.generator.trainable = True\n",
    "\n",
    "        # Sampled noise for input to generator\n",
    "        z_gen = Input(shape=(self.latent_dim,))\n",
    "        # Generate images based of noise\n",
    "        img = self.generator(z_gen)\n",
    "        # Discriminator determines validity\n",
    "        valid = self.critic(img)\n",
    "        # Defines generator model\n",
    "        self.generator_model = Model(z_gen, valid)\n",
    "        self.generator_model.compile(loss=self.wasserstein_loss, optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        \"\"\"\n",
    "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "        \"\"\"\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        # compute the euclidean norm by squaring ...\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        #   ... summing over the rows ...\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        #   ... and sqrt\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        # return the mean as loss over all the batch samples\n",
    "        return K.mean(gradient_penalty)\n",
    "\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256 * 16 * 16, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((16, 16, 256)))\n",
    "        model.add(UpSampling2D())\n",
    "        \n",
    "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        \n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('tanh'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, train_data, epochs, batch_size, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        X_train = fracture_train\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake =  np.ones((batch_size, 1))\n",
    "        dummy = np.zeros((batch_size, 1)) # Dummy gt for gradient penalty\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for _ in range(self.n_critic):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a random batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                # Sample generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                # Train the critic\n",
    "                d_loss = self.critic_model.train_on_batch([imgs, noise], [valid, fake, dummy])\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = self.generator_model.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 3, 3\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/whole_%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = WGANGP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wgan 학습\n",
    "wgan.train(fracture_train, epochs=15000, batch_size=32, sample_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.critic.save(\"./models/gan_d_model_tanh_.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization \n",
    "from keras.layers import concatenate, Conv2DTranspose, Reshape\n",
    "from os import path\n",
    "\n",
    "def whole_model():\n",
    "    inputs = Input((128,128,1))\n",
    "    depth = 16\n",
    "    conv1 = Conv2D(int(depth*1), (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(int(depth*1), (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(int(depth*1), (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(int(depth*1), (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(int(depth*2), (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(int(depth*2), (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(int(depth*2), (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(int(depth*2), (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(0.25)(pool2)\n",
    "\n",
    "    conv3 = Conv2D(int(depth*4), (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(int(depth*4), (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(int(depth*4), (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(int(depth*4), (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(0.25)(pool3)\n",
    "\n",
    "    conv4 = Conv2D(int(depth*8), (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(int(depth*8), (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(int(depth*8), (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(int(depth*8), (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(0.25)(pool4)\n",
    "\n",
    "    conv5 = Conv2D(int(depth*16), (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(int(depth*16), (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(int(depth*16), (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(int(depth*16), (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "    pool5 = Dropout(0.25)(pool5)\n",
    "\n",
    "    conv6 = Conv2D(int(depth*32), (3, 3), activation='relu', padding='same')(pool5)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(int(depth*32), (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(int(depth*32), (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(int(depth*32), (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    pool6 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
    "    pool6 = Dropout(0.25)(pool6)\n",
    "    \n",
    "    c_conv_output = pool6\n",
    "    dense1 = Flatten()(c_conv_output)\n",
    "    dense2 = Dense(int(depth*32), activation='relu')(dense1)\n",
    "    dense2 = BatchNormalization()(dense2)\n",
    "    c_outputs = Dense(1, activation='tanh')(dense2) # softmax 로 할 경우 1- > 2 로변경\n",
    "    c_model_ = Model(inputs=[inputs], outputs=[c_outputs], name='classify_model')\n",
    "\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(int(depth*32), (2, 2), strides=(2, 2), padding='same')(conv6), conv5], axis=3)\n",
    "    conv7 = Conv2D(int(depth*16), (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(int(depth*16), (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(int(depth*16), (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(int(depth*16), (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    \n",
    "    up8 = concatenate([Conv2DTranspose(int(depth*16), (2, 2), strides=(2, 2), padding='same')(conv7), conv4], axis=3)\n",
    "    conv8 = Conv2D(int(depth*8), (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(int(depth*8), (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(int(depth*8), (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(int(depth*8), (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    \n",
    "    up9 = concatenate([Conv2DTranspose(int(depth*8), (2, 2), strides=(2, 2), padding='same')(conv8), conv3], axis=3)\n",
    "    conv9 = Conv2D(int(depth*4), (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(int(depth*4), (3, 3), activation='relu', padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(int(depth*4), (3, 3), activation='relu', padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(int(depth*4), (3, 3), activation='relu', padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    \n",
    "    up10 = concatenate([Conv2DTranspose(int(depth*4), (2, 2), strides=(2, 2), padding='same')(conv9), conv2], axis=3)\n",
    "    conv10 = Conv2D(int(depth*2), (3, 3), activation='relu', padding='same')(up10)\n",
    "    conv10 = BatchNormalization()(conv10)\n",
    "    conv10 = Conv2D(int(depth*2), (3, 3), activation='relu', padding='same')(conv10)\n",
    "    conv10 = BatchNormalization()(conv10)\n",
    "    conv10 = Conv2D(int(depth*2), (3, 3), activation='relu', padding='same')(conv10)\n",
    "    conv10 = BatchNormalization()(conv10)\n",
    "    conv10 = Conv2D(int(depth*2), (3, 3), activation='relu', padding='same')(conv10)\n",
    "    conv10 = BatchNormalization()(conv10)    \n",
    "    \n",
    "    up11 = concatenate([Conv2DTranspose(int(depth*2), (2, 2), strides=(2, 2), padding='same')(conv10), conv1], axis=3)\n",
    "    conv11 = Conv2D(int(depth*1), (3, 3), activation='relu', padding='same')(up11)\n",
    "    conv11 = BatchNormalization()(conv11)\n",
    "    conv11 = Conv2D(int(depth*1), (3, 3), activation='relu', padding='same')(conv11)\n",
    "    conv11 = BatchNormalization()(conv11)\n",
    "    conv11 = Conv2D(int(depth*1), (3, 3), activation='relu', padding='same')(conv11)\n",
    "    conv11 = BatchNormalization()(conv11)\n",
    "    conv11 = Conv2D(int(depth*1), (3, 3), activation='relu', padding='same')(conv11)\n",
    "    conv11 = BatchNormalization()(conv11)    \n",
    "    \n",
    "    conv12 = Conv2D(1, (1, 1), activation='tanh')(conv11)\n",
    "    g_model = Model(inputs=[inputs], outputs=[conv12])\n",
    "\n",
    "    return c_model_, g_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model_, g_model = whole_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class PlotLosses(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.x_ = []\n",
    "        self.accuracy = []\n",
    "        self.val_accuracy = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "        self.accuracy.append(logs.get('accuracy'))\n",
    "        self.val_accuracy.append(logs.get('val_accuracy'))\n",
    "\n",
    "        self.i += 1\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.plot(self.x, self.accuracy, label=\"accuracy\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.plot(self.x, self.val_accuracy, label=\"val_accuracy\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", self.losses[-1], \", val_loss = \", self.val_losses[-1])\n",
    "        print(\"accuracy = \", self.accuracy[-1], \", val_accuracy = \", self.val_accuracy[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# 학습 중에 loss 그리기\n",
    "plot_losses = PlotLosses()\n",
    "\n",
    "# overfitting이 발생하면 학습 중지\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "\n",
    "# 학습 실행하면서 학습율 감소시키기\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from os import path\n",
    "\n",
    "callbacks = [plot_losses, reduce_lr]\n",
    "c_model_.summary()\n",
    "c_model_.compile(optimizer=optimizers.Adadelta(), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "# c_model_.compile(optimizer=optimizers.Adadelta(), loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])  # Activation=softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c, X_test, Y_train_c, Y_test = np.load('./npy/classify_train.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model_.fit(X_train_c, Y_train_c, \n",
    "            epochs = 100, \n",
    "            verbose = 1, \n",
    "            batch_size = 32, \n",
    "            validation_split = 0.1, \n",
    "            shuffle=True, \n",
    "            callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model_.save('./models/class_c_model_tanh_.h5')\n",
    "\n",
    "loss, acc = c_model_.evaluate(X_test, Y_test)\n",
    "print(\"loss =\", loss)\n",
    "print(\"acc =\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "\n",
    "c_model  = keras.models.load_model('./models/class_c_model_tanh_.h5')\n",
    "c_model.trainable = False\n",
    "\n",
    "for layer in c_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "d_model  = keras.models.load_model('./models/gan_d_model_tanh_.h5')\n",
    "d_model.trainable = False\n",
    "\n",
    "for layer in d_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "g_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((128,128,1))\n",
    "generated = g_model(inputs)\n",
    "d_output = d_model(generated)\n",
    "c_output = c_model(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "d_r = 0.0005 \n",
    "u_r = 0.999\n",
    "c_r = 0.0005\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return c_r * K.mean(c_output) + u_r * K.mean(keras.losses.mean_squared_error(inputs, generated)) + d_r * K.mean(d_output)\n",
    "\n",
    "whole_model = Model(inputs=[inputs], outputs=[d_output, c_output])\n",
    "\n",
    "whole_model.compile(loss=custom_loss, optimizer='adam', metrics=['accuracy'])\n",
    "whole_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_train = np.load('./npy/normal_train.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real = 0, normal = 0 으로 normal_train 개수에 맞춰서 생성 \n",
    "real = np.zeros(normal_train.shape[0])\n",
    "normal= np.zeros(normal_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal data로만 학습\n",
    "hist = whole_model.fit(normal_train, [real, normal], validation_split=0.1, epochs=100, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normal, fracture섞인 data로 학습\n",
    "\n",
    "# # real = 0, normal = 0 으로 X_train_c 개수에 맞춰서 생성 \n",
    "# real = np.zeros(X_train_c.shape[0])\n",
    "# normal= np.zeros(X_train_c.shape[0])\n",
    "\n",
    "# hist = whole_model.fit(X_train_c, [real, normal], validation_split=0.1, epochs=20, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "whole_model.save('./models/whole_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole 학습 결과\n",
    "\n",
    "* Input is classified as (Normal, Fracture) : Input Image의 정답\n",
    "* classified as (Normal, Fracture) : Input Image의 분류 (0:Noraml, 1:Fracture)\n",
    "* Generated is Discriminated as (Real, Fake) : Generated Image의 판별 (0:Real, 1:Fake)\n",
    "* Generated is classified as (Noraml, Fracture) : Generated Image의 분류 (0:Noraml, 1:Fracture)\n",
    "\n",
    "\n",
    "* 최종목표 : Input은 Fracture or Normal 이여도 Generated Image는 Normal이 출력되야된다. \n",
    "input = S\n",
    "1. S(골절) -> G(비골절) = Fracture area (area 출력)\n",
    "2. S(비골절) -> G(비골절) = Fracture area (미표기) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util 함수\n",
    "\n",
    "def show_result(target_data=X_test, count=10, threshold=0.2):\n",
    "\n",
    "    shuffled_index = np.random.permutation(X_test.shape[0])\n",
    "    shuffled_index = np.arange(0,count)\n",
    "    model_input_shape = (1,128, 128, 1)\n",
    "\n",
    "    for i in range(count):\n",
    "        cl_ = Y_test[i]\n",
    "        target_input = target_data[shuffled_index[i]]\n",
    "        c_out = c_model.predict(target_input.reshape(model_input_shape)) \n",
    "        g_out = g_model.predict(target_input.reshape(model_input_shape))\n",
    "        d_out = d_model.predict(g_out)\n",
    "        c_out_g_in = c_model.predict(g_out)\n",
    "        \n",
    "        diff = np.absolute(g_out[0] - target_input)\n",
    "        diff[diff < threshold] = 0.0\n",
    "\n",
    "        # 실제 이미지\n",
    "        if Y_test[i] == 0 :\n",
    "            print('Input is classified as Normal Image %.1f' % Y_test[i], '(0 : Normal, 1 : Fracture)')\n",
    "        else : \n",
    "            print('Input is classified as Fracture Image %.1f' % Y_test[i], '(0 : Normal, 1 : Fracture)')\n",
    "\n",
    "        # classify  0 normal, 1 fracture \n",
    "        if c_out[0][1] <= 0.5 :  \n",
    "            print('Classified as Normal Image %.2f' % c_out[0][1], '(0 : Normal, 1 : Fracture)')\n",
    "        else :\n",
    "            print('Classified as Fractrue Image %.2f' % c_out[0][1], '(0 : Normal, 1 : Fracture)')\n",
    "        \n",
    "        # discriminator 0 real 1 fake 디스크리미네이터의 진짜와 가짜\n",
    "        d_out_ = np.argmax(d_out, axis = 1)\n",
    "        if d_out_ <= 0.5 :  \n",
    "            print('Generated is Discriminated as Real Image %.2f' % d_out_, '(0 : Real, 1 : Fake)')\n",
    "        else : \n",
    "            print('Generated is Discriminated as Fake Image %.2f' % d_out_, '(0 : Real, 1 : Fake)')            \n",
    "        \n",
    "        # generator_classify 0 normal, 1 fracture\n",
    "        if c_out_g_in[0][1] <= 0.5 :  \n",
    "            print('Generated is classified as Normal Image %.2f' % c_out_g_in[0][1], '(0 : Normal, 1 : Fracture)')\n",
    "        else :\n",
    "            print('Generated is classified as Fracture Image %.2f' % c_out_g_in[0][1], '(0 : Normal, 1 : Fracture)')\n",
    "        \n",
    "            \n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.title('Input img')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(target_input.reshape((128,128)),cmap='gray' , vmin=0, vmax=1)\n",
    "        \n",
    "        plt.subplot(1,3,2)\n",
    "        plt.title('Generated img')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(g_out[0].reshape((128,128)),cmap='gray', vmin=0, vmax=1)\n",
    "        \n",
    "        plt.subplot(1,3,3)\n",
    "        plt.title('Fracture area')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(diff.reshape((128,128)),cmap='gray', vmin=0, vmax=1)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        print()\n",
    "#cmap=plt.cm.binary\n",
    "# show_result(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(X_test, threshold=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}